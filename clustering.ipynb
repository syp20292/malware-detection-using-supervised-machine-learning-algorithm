{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always import\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# numpy & scipy\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import pairwise_distances_argmin, pairwise_distances\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Hungarian algorithm\n",
    "#from munkres import Munkres\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "%matplotlib inline\n",
    "from matplotlib import offsetbox\n",
    "from sklearn.manifold import Isomap, TSNE\n",
    "\n",
    "# maybe\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data and normalization\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, data_home='mnist/')\n",
    "y = np.asarray(list(map(int, y)))\n",
    "X = np.asarray(X.astype(float))\n",
    "X = scale(X)\n",
    "n_digits = len(np.unique(y))\n",
    "\n",
    "print(\"n_digits: \", n_digits)\n",
    "print(\"X.shape: \",X.shape)\n",
    "print(\"y.shape: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise input data\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(X[0:5], y[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_tsne = X[:500]\n",
    "y_tsne = y[:500]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_2d = tsne.fit_transform(X_tsne)\n",
    "\n",
    "target_ids = np.unique(y)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'silver', 'orange', 'purple']\n",
    "for i, c, label in zip(target_ids, colors, np.unique(y)):\n",
    "    plt.scatter(X_2d[y_tsne == i, 0], X_2d[y_tsne == i, 1], c=c, label=label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanDist(x, C):\n",
    "    '''\n",
    "    x: m-dim data\n",
    "    C: K x m matrix of cluster centroids\n",
    "    \n",
    "    return: \n",
    "    l2_dist: array of Euclidean distance of x to each of the cluster\n",
    "    min_clus_ind: row index of C that rep. min. dist between x and K\n",
    "            \n",
    "    '''\n",
    "#     l2_dist = np.sqrt(np.sum(np.square(C - x), axis=1))#K-dim\n",
    "    l2_dist = np.sqrt(np.diagonal(np.matmul(C-x,(C-x).T)))\n",
    "    min_clus_ind = np.argmin(l2_dist)\n",
    "    \n",
    "    return l2_dist, min_clus_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans\n",
    "def Kmeans(X, K, init='Forgy'):\n",
    "    tau = 1e-4\n",
    "    max_iter = 300\n",
    "    iter = 0\n",
    "    \n",
    "    n, m = X.shape\n",
    "    C = np.zeros((K,m))\n",
    "    z = np.zeros(n) #clustering label for each xi\n",
    "    dist_to_clus = np.zeros(n)\n",
    "    prev_obj = 0\n",
    "    \n",
    "    #initialse centroids\n",
    "    if init == 'Forgy':\n",
    "        ind = np.random.choice(n,K, replace=False)\n",
    "        C = X[ind,:]\n",
    "    elif init == 'PCA':\n",
    "        pca = PCA(n_components=K)\n",
    "        pca.fit(X)\n",
    "        C = pca.components_ #top K eigenectors\n",
    "    \n",
    "    while True:\n",
    "        #assign each xi to closest centroid\n",
    "        for i in range(n):\n",
    "            l2_dist, z_i = EuclideanDist(X[i,:], C)\n",
    "            z[i] = z_i\n",
    "            dist_to_clus[i] = l2_dist[z_i]\n",
    "\n",
    "        #update cluster\n",
    "        for k in range(K):  \n",
    "            C[k,:] = np.mean(X[(z==k),:], axis=0)\n",
    "        \n",
    "        \n",
    "        #stopping criteria check\n",
    "        if iter >= 1:\n",
    "            curr_obj = np.sum(np.square(dist_to_clus))\n",
    "            if (iter >= max_iter) or (prev_obj - curr_obj <= tau):\n",
    "                break\n",
    "            \n",
    "        iter += 1\n",
    "        prev_obj =  np.sum(np.square(dist_to_clus))\n",
    "    \n",
    "    print('final loss: ', curr_obj)\n",
    "    print('total Iter: ', iter)\n",
    "    print('z:', z.shape)\n",
    "    print('C:', C.shape)\n",
    "    \n",
    "    return z, C, curr_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate Kmeans on MNIST\n",
    "# Problem 2(a)-i \n",
    "z_pca, C, curr_obj = Kmeans(X,10,'PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA Evaluation\n",
    "print('adjusted_rand_score: ', metrics.adjusted_rand_score(y, z_pca))\n",
    "print('adjusted_mutual_info_score: ', metrics.adjusted_mutual_info_score(y, z_pca))\n",
    "homogeneity, completeness, v_measure =  metrics.homogeneity_completeness_v_measure(y, z_pca)\n",
    "print('metrics.homogeneity_score: ', homogeneity)\n",
    "print('metrics.completeness_score: ', completeness)\n",
    "print('metrics.v_measure_score: ', v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Problem 2(a)-ii\n",
    "pca = PCA(n_components=30)\n",
    "X_proj = pca.fit_transform(X)\n",
    "run = 10\n",
    "min_obj = 999999999\n",
    "\n",
    "print('X_proj: ', X_proj.shape)\n",
    "print('X: ', X.shape)\n",
    "\n",
    "n, m_pri = X_proj.shape\n",
    "z_min = np.zeros(n)\n",
    "C_min = np.zeros((10,m_pri))\n",
    "\n",
    "for i in range(run):\n",
    "    z, C, curr_obj = Kmeans(X_proj, 10)\n",
    "    \n",
    "    if curr_obj < min_obj:\n",
    "        min_obj = curr_obj\n",
    "        z_min = z\n",
    "        C_min = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forgy init with PCA dim reduction evaluation\n",
    "print('adjusted_rand_score: ', metrics.adjusted_rand_score(y, z_min))\n",
    "print('adjusted_mutual_info_score: ', metrics.adjusted_mutual_info_score(y, z_min))\n",
    "homogeneity, completeness, v_measure =  metrics.homogeneity_completeness_v_measure(y, z_min)\n",
    "print('metrics.homogeneity_score: ', homogeneity)\n",
    "print('metrics.completeness_score: ', completeness)\n",
    "print('metrics.v_measure_score: ', v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hungarian algorithm\n",
    "\n",
    "# cost matrix, W, construction\n",
    "def W_gen(K,z,y):\n",
    "    '''\n",
    "    K: number of clusters\n",
    "    z: cluster prediction\n",
    "    y: true labels\n",
    "    '''\n",
    "    n = len(y)\n",
    "    W = np.zeros((K,K))\n",
    "\n",
    "    for i,col in enumerate(W): # for each row\n",
    "        for j, W_ij in enumerate(col): # for each col\n",
    "            z_l = np.where(z==i) # np.where return indices of matched components\n",
    "            y_l = np.where(y==j) \n",
    "\n",
    "            comm_Elem = np.intersect1d(z_l, y_l)\n",
    "            W[i][j] = 1.0 - len(comm_Elem)/n\n",
    "\n",
    "        W[i,:] -= np.min(W[i,:])\n",
    "\n",
    "    return W\n",
    "    \n",
    "def ClusterMap(z, hung_map):\n",
    "    z_prime = np.zeros(len(z))\n",
    "    \n",
    "    for i, mapping in enumerate(hung_map):\n",
    "        z_prime[np.where(z == i)] = mapping\n",
    "        \n",
    "    return z_prime\n",
    "\n",
    "def precision(pred, y):\n",
    "    return sum(np.equal(pred, y)) / float(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W_PCA = W_gen(10,z_pca,y)\n",
    "row_pca, col_pca = linear_sum_assignment(W_PCA)\n",
    "print(\"col_pca: \", col_pca)\n",
    "\n",
    "z_pri_pca = ClusterMap(z_pca,col_pca) \n",
    "print('PCA precision: ', precision(z_pri_pca, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_mat = confusion_matrix(z_pri_pca, y)\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(cf_mat, annot = True, cmap = 'BuGn_r',square=True, fmt='d')\n",
    "ax.set_ylim(10,0) #to prevent top and bottom from getting cut off\n",
    "plt.show()\n",
    "cf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W_forgy = W_gen(10,z_min,y)\n",
    "row_forgy, col_forgy = linear_sum_assignment(W_forgy)\n",
    "print(\"col_forgy: \", col_forgy)\n",
    "\n",
    "z_pri_min = ClusterMap(z_min,col_forgy)\n",
    "print('forgy precision: ', precision(z_pri_min, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_mat = confusion_matrix(z_pri_min, y)\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(cf_mat, annot = True, cmap = 'BuGn_r',square=True, fmt='d')\n",
    "ax.set_ylim(10,0) #to prevent top and bottom from getting cut off\n",
    "plt.show()\n",
    "cf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sparse matrix \n",
    "# row-wise normalise, modify in-place\n",
    "def rowWiseNorm(E):\n",
    "    indptr = E.indptr\n",
    "    last_idx = indptr[0]\n",
    "    for row_id, idx in enumerate(indptr[1:]):\n",
    "        if idx == last_idx: # empty row\n",
    "            continue\n",
    "        else:\n",
    "            row_sum = np.sum(E.data[last_idx:idx])\n",
    "#             print(type(E.data[last_idx:idx]))\n",
    "#             print(E.data[last_idx:idx])\n",
    "#             print(row_sum)\n",
    "#             np.asarray(E.data[last_idx:idx])\n",
    "\n",
    "            E.data[last_idx:idx] /= row_sum\n",
    "            \n",
    "#             print(E.data[last_idx:idx])\n",
    "            last_idx = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "X_pri = pca.fit_transform(X)\n",
    "\n",
    "# knbrs = neighbors.NearestNeighbors(n_neighbors=500, algorithm='kd_tree', metric='euclidean')\n",
    "# kgraph = knbrs.fit(X_pri).kneighbors_graph(mode='distance')\n",
    "\n",
    "#Save kgraph for faster testing\n",
    "# scipy.sparse.save_npz('./kgraph.npz',kgraph)\n",
    "# H=scipy.sparse.load_npz('./kgraph.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral clustering\n",
    "\n",
    "def SpectralCluster(X_pri, K, n_neighbors=500, k_eigVec=20):\n",
    "    \n",
    "    # csr format\n",
    "    H = neighbors.NearestNeighbors(n_neighbors=n_neighbors, algorithm='kd_tree', metric='euclidean').fit(X_pri).kneighbors_graph(mode='distance')\n",
    "#     H=scipy.sparse.load_npz('./kgraph.npz')\n",
    "    scipy.sparse.save_npz('./kgraph.npz',H)\n",
    "    print('kgraph saved...\\n')\n",
    "    n = H.shape[0]\n",
    "\n",
    "    # normalise H\n",
    "    sigma = H.sum()/H.count_nonzero()  # == np.sum(H.data)\n",
    "    H.data = H.power(2).data\n",
    "    H.data = np.exp(-H.data/np.power(sigma,2))\n",
    "\n",
    "    rowWiseNorm(H)\n",
    "#     H.data = H.data/H.sum()\n",
    "    H.setdiag(1.0)\n",
    "\n",
    "    # smmetrize H\n",
    "    H = (H.transpose() + H)/2 # H sparse_csr\n",
    "\n",
    "    # Compute D\n",
    "    D = np.squeeze(np.asarray(H.sum(axis=1)))\n",
    "    D = scipy.sparse.diags(D)\n",
    "\n",
    "    # Compute D^(-1/2)\n",
    "    D_inv = D.power(-0.5) # sparse_diag\n",
    "\n",
    "    # Compute L\n",
    "    L = scipy.sparse.identity(n) - D_inv@H.tocoo()@D_inv\n",
    "    \n",
    "    # Top k eigenvectors\n",
    "#     print('------------eig start-----------------')\n",
    "    eigVals, eigVecs = scipy.sparse.linalg.eigs(L, k=k_eigVec, which='SM')\n",
    "#     print('nonzero: ',np.count_nonzero(eigVecs,axis=1))\n",
    "#     print('------------eig end-----------------')\n",
    "    \n",
    "    eigVecs = eigVecs[:,1:].real\n",
    "    norm_vec = np.sqrt(np.sum(np.power(eigVecs,(2)),axis=1))\n",
    "    eigVecs_norm = eigVecs/norm_vec.reshape(-1,1)\n",
    "    \n",
    "    print('eigVals: ' ,eigVals)\n",
    "    print('-------------------------\\n')\n",
    "    print('eigVecs: ' ,eigVecs)\n",
    "    print('-------------------------\\n')\n",
    "    print('eigVecs.shape: ' ,eigVecs.shape)\n",
    "    print('-------------------------\\n')\n",
    "        \n",
    "    # run K-means 10 times, return the best\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=K, n_init=10).fit(eigVecs_norm)\n",
    "    # n_init: number of times to run KMeans for.\n",
    "    \n",
    "    z = kmeans.labels_\n",
    "    C = kmeans.cluster_centers_\n",
    "    print('shape(z): ', z.shape)\n",
    "    print('shape(C): ', C.shape)\n",
    "    print('shape(eigVecs_norm): ', eigVecs_norm.shape)\n",
    "    \n",
    "    return z, C, eigVecs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_sptrclus, C, data_speclu= SpectralCluster(X_pri, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_sptrclus = W_gen(10,z_sptrclus,y)\n",
    "row_z_sptrclus, col_z_sptrclus = linear_sum_assignment(W_sptrclus)\n",
    "print(\"col_z_sptrclus: \", col_z_sptrclus)\n",
    "print(\"row_z_sptrclus: \", row_z_sptrclus)\n",
    "\n",
    "z_sptrclus_map = ClusterMap(z_sptrclus, col_z_sptrclus)\n",
    "# print(z_sptrclus_map.shape)\n",
    "\n",
    "print('spcetral clustering precision: ', precision(z_sptrclus_map, y))\n",
    "\n",
    "cf_mat = confusion_matrix(z_sptrclus_map, y)\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(cf_mat, annot = True, cmap = 'BuGn_r',square=True, fmt='d')\n",
    "ax.set_ylim(10,0) #to prevent top and bottom from getting cut off\n",
    "plt.show()\n",
    "cf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sptrclus, C, _ = SpectralCluster(X_pri, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_sptrclus = W_gen(10,z_sptrclus,y)\n",
    "row_z_sptrclus, col_z_sptrclus = linear_sum_assignment(W_sptrclus)\n",
    "print(\"col_z_sptrclus: \", col_z_sptrclus)\n",
    "print(\"row_z_sptrclus: \", row_z_sptrclus)\n",
    "\n",
    "z_sptrclus_map = ClusterMap(z_sptrclus, col_z_sptrclus)\n",
    "# print(z_sptrclus_map.shape)\n",
    "\n",
    "print('spcetral clustering precision: ', precision(z_sptrclus_map, y))\n",
    "\n",
    "cf_mat = confusion_matrix(z_sptrclus_map, y)\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(cf_mat, annot = True, cmap = 'BuGn_r',square=True, fmt='d')\n",
    "ax.set_ylim(10,0) #to prevent top and bottom from getting cut off\n",
    "plt.show()\n",
    "cf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering + KNN\n",
    "class KNNClassifier():\n",
    "\n",
    "    def __init__(self,k, ind=None):\n",
    "        self.kNeighbors = k\n",
    "        if np.all(ind):\n",
    "            # for the random choice case\n",
    "            self.indToTrain = ind\n",
    "        else:\n",
    "            # for Kmeans and spectral clustering\n",
    "            self.indToTrain = np.array([],dtype=np.int)\n",
    "            \n",
    "        self.model = None # store cloest pts to each c in C\n",
    "        self.label = np.array([]) \n",
    "        \n",
    "        # KNN predictions\n",
    "        self.y_pred = []\n",
    "        \n",
    "    def fit(self, C, train, y):\n",
    "        '''\n",
    "        for each c in C, find min dist xi and C\n",
    "            store xi index, xi, and true label of xi\n",
    "        \n",
    "        C: shape(100,30) rand & kmeans, shape(100,(k-1)eigVects) spc \n",
    "        train: shape(n,30) rand & kmeans, shape(n,(k-1)eigVects) spc\n",
    "        '''\n",
    "        self.model = np.zeros((100,train.shape[1]))\n",
    "\n",
    "        if self.indToTrain.size != 0:\n",
    "#             print('self.indToTrain:' ,type(self.indToTrain))\n",
    "            self.model = train[self.indToTrain,:]\n",
    "            self.label = y[self.indToTrain]\n",
    "            return\n",
    "        \n",
    "        for row_idx , C_row in enumerate(C):\n",
    "            # l2.shape = (n,1)\n",
    "            # C[row, :] = C_row\n",
    "            l2 = np.sqrt(np.sum(np.square(train-C_row.reshape(1,-1)), axis=1))\n",
    "            least_ind = np.argmin(l2)\n",
    "            \n",
    "            self.indToTrain = np.append(self.indToTrain, least_ind)\n",
    "            self.model[row_idx,:] = train[least_ind,:]\n",
    "            self.label = np.append(self.label, y[least_ind])\n",
    "        \n",
    "    def predict(self, test, y):\n",
    "        '''\n",
    "        for each test bar the index ones\n",
    "           compute dist bet. all points in self.model\n",
    "           find k smallest dist. get corresponsing labels \n",
    "           save max. occurrening labels to self.y_pred\n",
    "           \n",
    "        test: same as train but points part of kNN model will be excluded from evaluation\n",
    "        '''\n",
    "        for i in range(test.shape[0]):\n",
    "            if i in self.indToTrain: #skip 100 train samples from D\n",
    "                continue\n",
    "            else:\n",
    "                l2 = np.sqrt(np.sum(np.square(self.model-test[i,:].reshape(1,-1)),axis=1))\n",
    "\n",
    "                k_smallest_ind = np.argsort(l2)[:self.kNeighbors]\n",
    "                \n",
    "                vals, cnts = np.unique(self.label[k_smallest_ind], return_counts=True)\n",
    "                self.y_pred.append(vals[np.argmax(cnts)])\n",
    "        \n",
    "        # mask out self.model from test for calc. precision\n",
    "        mask = np.ones(test.shape[0], dtype=bool)\n",
    "        mask[self.indToTrain] = False\n",
    "        y_masked = y[mask]\n",
    "        \n",
    "        return precision(self.y_pred, y_masked)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "X_pri = pca.fit_transform(X)\n",
    "n,m = X_pri.shape\n",
    "\n",
    "print(f'X_pri shape: {X_pri.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random choice\n",
    "knbors = [1,3,5]\n",
    "pred_acc=[]\n",
    "\n",
    "for k_ind, k in enumerate(knbors):\n",
    "    print(f'------------------ In {k} ------------------\\n')\n",
    "    ind_rc = np.random.choice(n,100, replace=False)\n",
    "    C_rc = X_pri[ind_rc, :]\n",
    "\n",
    "    knn_rand = KNNClassifier(k,ind_rc)\n",
    "    knn_rand.fit(C_rc, X_pri,y)\n",
    "    pred_acc.append(knn_rand.predict(X_pri,y))\n",
    "\n",
    "print('\\n')\n",
    "for i, k in enumerate(pred_acc):\n",
    "    print(f'precision for random choice with {knbors[i]} neighbors: {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral clustering\n",
    "H = neighbors.NearestNeighbors(n_neighbors=500, algorithm='kd_tree', metric='euclidean').fit(X_pri).kneighbors_graph(mode='distance')\n",
    "# scipy.sparse.save_npz('./kgraph.npz',H)\n",
    "# H=scipy.sparse.load_npz('./kgraph.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_speclu, C_speclu, data_speclu = SpectralCluster(X_pri, 100, n_neighbors=500, k_eigVec=20)\n",
    "print(f'data_speclu shape: {data_speclu.shape}')\n",
    "print(f'C_speclu shape: {C_speclu.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knbors = [1,3,5]\n",
    "pred_acc=[]\n",
    "\n",
    "for k_ind, k in enumerate(knbors):\n",
    "    print(f'------------------ In {k} ------------------\\n')\n",
    "    knn_spc = KNNClassifier(k)\n",
    "    knn_spc.fit(C_speclu, data_speclu, y)\n",
    "    pred_acc.append(knn_spc.predict(data_speclu, y))\n",
    "\n",
    "print('\\n')\n",
    "for i, k in enumerate(pred_acc):\n",
    "    print(f'precision for spectral clustering with {knbors[i]} neighbors: {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans \n",
    "# run Kmeans 10 times and pick the best\n",
    "run = 10\n",
    "min_obj = 999999999\n",
    "\n",
    "n, m = X_pri.shape\n",
    "z_Kmeans = np.zeros(n)\n",
    "C_Kmeans = np.zeros((100,m))\n",
    "\n",
    "for i in range(run):\n",
    "    print(f'--------------run: {i}--------------------')\n",
    "    z, C, curr_obj = Kmeans(X_pri, 100, 'Forgy')\n",
    "    \n",
    "    if curr_obj < min_obj:\n",
    "        min_obj = curr_obj\n",
    "        z_Kmeans = z\n",
    "        C_Kmeans = C\n",
    "        \n",
    "print(f'C_Kmeans shape: {C_Kmeans.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Kmeans \n",
    "knbors = [1,3,5]\n",
    "pred_acc=[]\n",
    "\n",
    "for k_ind, k in enumerate(knbors):\n",
    "    print(f'------------------ In {k} ------------------\\n')\n",
    "    knn_Kmeans = KNNClassifier(k)\n",
    "    knn_Kmeans.fit(C_Kmeans, X_pri, y)\n",
    "    pred_acc.append(knn_Kmeans.predict(X_pri, y))\n",
    "\n",
    "print('\\n')\n",
    "for i, k in enumerate(pred_acc):\n",
    "    print(f'precision for Kmeans with {knbors[i]} neighbors: {k}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
